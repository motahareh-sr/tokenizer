# tokenizer
This project implements two widely used subword tokenization algorithms: Byte Pair Encoding (BPE) and WordPiece Tokenization. These methods are fundamental for modern NLP tasks, especially in training and using models like BERT and GPT.
